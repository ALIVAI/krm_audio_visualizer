<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="An interactive audio visualizer project inspired by KolkataRedMusic (KRM Audio Visualizer), explaining Web Audio API basics and how to create no-copyright music.">
    <meta name="keywords" content="audio visualizer, KRM Audio Visualizer, Web Audio API, no copyright music, music production, JavaScript, HTML, CSS, GitHub project, KolkataRedMusic">
    <meta name="author" content="KolkataRedMusic">
    <title>KRM Audio Visualizer & No-Copyright Music Project</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0d1117; /* GitHub Dark Background */
            color: #c9d1d9; /* GitHub Text Color */
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }
        canvas {
            background-color: #161b22; /* Slightly lighter than body background for contrast */
            border: 2px solid #21262d;
            border-radius: 0.75rem; /* Rounded corners */
            display: block;
            width: 100%; /* Make canvas responsive */
            height: 400px; /* Fixed height for visualizer */
            margin-top: 1.5rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #58a6ff; /* GitHub Blue */
            cursor: pointer;
            box-shadow: 0 0 0 4px rgba(88, 166, 255, 0.3);
        }
        input[type="range"]::-moz-range-thumb {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #58a6ff;
            cursor: pointer;
            box-shadow: 0 0 0 4px rgba(88, 166, 255, 0.3);
        }
        /* Custom scrollbar for aesthetic */
        ::-webkit-scrollbar {
            width: 8px;
            height: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #21262d;
            border-radius: 10px;
        }
        ::-webkit-scrollbar-thumb {
            background: #30363d;
            border-radius: 10px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #444c56;
        }
    </style>
</head>
<body class="antialiased leading-normal tracking-tight">
    <div class="container min-h-screen flex flex-col justify-center items-center py-10 px-4 sm:px-6 lg:px-8">
        <header class="text-center mb-10">
            <h1 class="text-4xl sm:text-5xl lg:text-6xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-purple-600 mb-4 rounded-lg p-2 shadow-lg">
                KRM Audio Visualizer & No-Copyright Music Project
            </h1>
            <p class="text-lg text-gray-400">
                A GitHub-ready project exploring audio visualization and the world of no-copyright music.
            </p>
        </header>

        <main class="w-full">
            <!-- Project Overview Section -->
            <section class="bg-gray-800 p-8 rounded-xl shadow-lg mb-10 border border-gray-700">
                <h2 class="text-3xl font-semibold text-blue-400 mb-4">Project Overview</h2>
                <p class="text-gray-300 leading-relaxed mb-4">
                    Welcome to a unique project designed for your GitHub portfolio, inspired by KolkataRedMusic (KRM)! This project focuses on two key aspects: understanding and creating audio visualizers, similar to your "KRM Audio Visualizer," and exploring the concept of no-copyright music for content creators.
                </p>
                <p class="text-gray-300 leading-relaxed">
                    It combines interactive web technology (HTML, CSS, JavaScript) for the visualizer and offers insights into the theoretical and practical aspects of sound.
                </p>
                <div class="mt-6 text-center">
                    <a href="https://www.youtube.com/@KolkataRedMusic" target="_blank" class="inline-flex items-center px-6 py-3 border border-transparent text-base font-medium rounded-full shadow-sm text-white bg-red-600 hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-red-500 transition duration-300 ease-in-out transform hover:scale-105">
                        <svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M10 0C4.477 0 0 4.477 0 10s4.477 10 10 10 10-4.477 10-10S15.523 0 10 0zm4.5 10.375c0 .27-.225.5-.5.5h-8c-.275 0-.5-.23-.5-.5v-1.75c0-.27.225-.5.5-.5h8c.275 0 .5.23.5.5v1.75zm0-4.75c0 .27-.225.5-.5.5h-8c-.275 0-.5-.23-.5-.5v-1.75c0-.27.225-.5.5-.5h8c.275 0 .5.23.5.5v1.75z" clip-rule="evenodd"></path></svg>
                        Visit KolkataRedMusic YouTube
                    </a>
                </div>
            </section>

            <!-- No-Copyright Music Section -->
            <section class="bg-gray-800 p-8 rounded-xl shadow-lg mb-10 border border-gray-700">
                <h2 class="text-3xl font-semibold text-blue-400 mb-4">Understanding No-Copyright Music & Music Bit Diagrams</h2>
                <p class="text-gray-300 leading-relaxed mb-4">
                    For content creators, using music without proper licensing can lead to copyright strikes. "No-copyright music" (NCS) refers to music that is explicitly permitted for use in creative works without paying royalties, often requiring attribution. This includes music released under Creative Commons licenses (like CC BY), public domain music, or tracks specifically offered for free use by artists or labels.
                </p>
                <p class="text-gray-300 leading-relaxed mb-4">
                    To make your own no-copyright music, you typically compose original pieces or use royalty-free sounds and samples. Ensure you understand the specific license for each track you use. Many platforms (like YouTube's Audio Library, Epidemic Sound, or various NCS channels) provide vast libraries.
                </p>
                <h3 class="text-2xl font-medium text-gray-200 mb-3">What are "Music Bit Diagrams"?</h3>
                <p class="text-gray-300 leading-relaxed mb-4">
                    While not a formal term, "music bit diagrams" in your context likely refers to visual representations of audio data, highlighting musical "bits" or events like beats, percussive hits, or changes in frequency. These diagrams help in understanding the structure and dynamics of a song. They can range from simple waveform displays to complex spectrograms or beat detection visualizations.
                </p>
                <p class="text-gray-300 leading-relaxed">
                    The audio visualizer below demonstrates one way to visually represent the frequency components of music, giving you a dynamic "bit diagram" in real-time. We also provide a conceptual Python script (check the separate immersive document) that outlines how one might start processing audio data to detect features, which can then be used to generate static "bit diagrams."
                </p>
                <div class="mt-6 text-center">
                    <p class="text-gray-300 mb-2">Check out one of KolkataRedMusic's creations:</p>
                    <div class="relative overflow-hidden rounded-xl shadow-lg" style="padding-top: 56.25%;">
                        <!-- Embedded YouTube Video (16:9 aspect ratio) -->
                        <iframe
                            class="absolute top-0 left-0 w-full h-full"
                            src="https://www.youtube.com/embed/arVdKF--M50?si=DqafTESfh9NWjI_p"
                            title="YouTube video player"
                            frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                            referrerpolicy="strict-origin-when-cross-origin"
                            allowfullscreen>
                        </iframe>
                    </div>
                </div>
            </section>

            <!-- KRM Audio Visualizer Section -->
            <section class="bg-gray-800 p-8 rounded-xl shadow-lg mb-10 border border-gray-700">
                <h2 class="text-3xl font-semibold text-blue-400 mb-4">Interactive KRM Audio Visualizer</h2>
                <p class="text-gray-300 leading-relaxed mb-4">
                    This interactive visualizer demonstrates how to process audio in the browser using the Web Audio API and display its frequency data on an HTML canvas. Upload an audio file (MP3, WAV, etc.) to see the "music bit diagram" come to life!
                </p>

                <div class="flex flex-wrap items-center justify-center gap-4 mb-6">
                    <label for="audioFile" class="block text-gray-300 text-lg font-medium">Upload Audio File:</label>
                    <input type="file" id="audioFile" accept="audio/*" class="block w-full sm:w-auto text-gray-300 text-sm file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-blue-500 file:text-white hover:file:bg-blue-600 cursor-pointer rounded-full p-2 border border-gray-700 bg-gray-700">
                </div>

                <div class="flex flex-wrap items-center justify-center gap-4 mb-6">
                    <button id="playPauseBtn" class="flex-1 px-6 py-3 bg-green-600 hover:bg-green-700 text-white font-bold rounded-full shadow-md transition duration-300 ease-in-out transform hover:scale-105 min-w-[120px]">Play</button>
                    <button id="stopBtn" class="flex-1 px-6 py-3 bg-red-600 hover:bg-red-700 text-white font-bold rounded-full shadow-md transition duration-300 ease-in-out transform hover:scale-105 min-w-[120px]">Stop</button>
                    <div class="flex-1 flex flex-col items-center min-w-[150px]">
                        <label for="volumeSlider" class="text-gray-300 text-sm mb-1">Volume:</label>
                        <input type="range" id="volumeSlider" min="0" max="1" value="0.7" step="0.01" class="w-full h-2 bg-gray-600 rounded-lg appearance-none cursor-pointer">
                    </div>
                </div>

                <canvas id="audioVisualizer"></canvas>

                <h3 class="text-2xl font-medium text-gray-200 mt-8 mb-3">How the KRM Audio Visualizer Works (Code Explained)</h3>
                <p class="text-gray-300 leading-relaxed mb-4">
                    The visualizer uses the browser's native <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">Web Audio API</code> to process sound. Here's a simplified breakdown of the JavaScript logic:
                </p>
                <ul class="list-disc list-inside text-gray-300 leading-relaxed space-y-2">
                    <li>
                        <strong class="text-blue-300">1. Audio Context:</strong> We create an <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">AudioContext</code>, which is the entry point for all Web Audio API functionality. It manages all audio nodes.
                    </li>
                    <li>
                        <strong class="text-blue-300">2. Audio Element Source:</strong> The uploaded audio file is loaded into an HTML <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">&lt;audio&gt;</code> element. We then create a <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">MediaElementSource</code> node from this audio element.
                    </li>
                    <li>
                        <strong class="text-blue-300">3. Analyser Node:</strong> An <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">AnalyserNode</code> is created. This node provides real-time frequency and time-domain data. We set its <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">fftSize</code> to determine the frequency resolution.
                    </li>
                    <li>
                        <strong class="text-blue-300">4. Connections:</strong> The <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">MediaElementSource</code> is connected to the <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">AnalyserNode</code>, and then the <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">AnalyserNode</code> is connected to the <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">AudioContext.destination</code> (your speakers). This ensures you can both hear the audio and analyze it.
                    </li>
                    <li>
                        <strong class="text-blue-300">5. Data Collection:</strong> In a continuous loop (using <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">requestAnimationFrame</code>), we retrieve the current frequency data from the <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">AnalyserNode</code> using <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">getByteFrequencyData()</code>.
                    </li>
                    <li>
                        <strong class="text-blue-300">6. Canvas Drawing:</strong> This frequency data (an array of values representing different frequency bands) is then used to draw bars on the HTML <code class="bg-gray-700 px-2 py-1 rounded text-blue-300">&lt;canvas&gt;</code> element, creating the dynamic visualizer effect. The height of each bar corresponds to the amplitude of that frequency band.
                    </li>
                </ul>
            </section>
        </main>

        <footer class="text-center text-gray-500 text-sm mt-10">
            <p>&copy; 2025 KolkataRedMusic. All rights reserved.</p>
            <p class="mt-2">Explore more at <a href="https://krmmediaplatform.blogspot.com/" target="_blank" class="text-blue-400 hover:underline">KRM Media Platform Blog</a></p>
        </footer>
    </div>

    <script>
        // Get DOM elements
        const audioFile = document.getElementById('audioFile');
        const playPauseBtn = document.getElementById('playPauseBtn');
        const stopBtn = document.getElementById('stopBtn');
        const volumeSlider = document.getElementById('volumeSlider');
        const canvas = document.getElementById('audioVisualizer');
        const canvasCtx = canvas.getContext('2d');

        // Initialize Audio Context and other Web Audio API components
        let audioContext; // The main audio processing graph
        let analyser;     // Node to get real-time frequency data
        let source;       // Node connecting the audio element to the audio graph
        let gainNode;     // Node to control overall volume
        let audio = new Audio(); // HTML Audio Element

        // State variables
        let isPlaying = false;
        let animationFrameId;

        // Function to initialize the audio context and connect nodes
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            // Create an analyser node to get frequency data
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256; // Fast Fourier Transform size (power of 2, e.g., 32, 64, 128, ..., 2048)
                                    // Higher value means more frequency bins, more detailed but slower
            const bufferLength = analyser.frequencyBinCount; // Number of data points available for frequency data
            const dataArray = new Uint8Array(bufferLength); // Array to hold the frequency data (byte values 0-255)

            // Create a gain node for volume control
            gainNode = audioContext.createGain();

            // Connect the HTML audio element to the AudioContext
            // A MediaElementSource represents the audio output from an HTMLAudioElement or HTMLVideoElement
            source = audioContext.createMediaElementSource(audio);

            // Connect the audio graph:
            // 1. Audio source connects to the analyser (for data collection)
            // 2. Analyser connects to the gain node (for volume control)
            // 3. Gain node connects to the audio context destination (your speakers)
            source.connect(analyser);
            analyser.connect(gainNode);
            gainNode.connect(audioContext.destination);

            // Set initial volume from slider
            gainNode.gain.value = volumeSlider.value;

            // Start the visualization loop
            drawVisualizer(bufferLength, dataArray);
        }

        // Function to draw the audio visualizer on the canvas
        function drawVisualizer(bufferLength, dataArray) {
            // Request the next animation frame for smooth rendering
            animationFrameId = requestAnimationFrame(() => drawVisualizer(bufferLength, dataArray));

            // Get the current frequency data from the analyser node
            analyser.getByteFrequencyData(dataArray);

            // Clear the canvas for the new frame
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

            // Set canvas dimensions to match display size for responsiveness
            // This prevents blurry visuals if canvas CSS size differs from internal resolution
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;

            // Calculate bar width and spacing
            const barWidth = (canvas.width / bufferLength) * 2.5; // Adjust multiplier for bar thickness/spacing
            let x = 0; // X-coordinate for drawing bars

            // Loop through each frequency data point and draw a bar
            for (let i = 0; i < bufferLength; i++) {
                const barHeight = dataArray[i]; // Height of the bar based on frequency amplitude

                // Calculate color based on frequency/height for a gradient effect
                const r = barHeight + (25 * (i / bufferLength));
                const g = 250 * (i / bufferLength);
                const b = 50;
                canvasCtx.fillStyle = `rgb(${r},${g},${b})`; // Bar color

                // Draw the rectangle (bar)
                canvasCtx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2); // Draw from bottom up

                // Move to the next bar position
                x += barWidth + 1; // Add 1 for a small gap between bars
            }
        }

        // Event listener for audio file input
        audioFile.addEventListener('change', function() {
            const files = this.files;
            if (files.length > 0) {
                const file = files[0];
                const fileURL = URL.createObjectURL(file);
                audio.src = fileURL;
                audio.load(); // Load the audio file

                // Reset play/pause button text
                playPauseBtn.textContent = 'Play';
                isPlaying = false;

                // If audio context exists, stop any ongoing visualization
                if (audioContext && animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                    canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
                }
            }
        });

        // Event listener for Play/Pause button
        playPauseBtn.addEventListener('click', function() {
            if (!audio.src) {
                // Show a simple message if no audio file is loaded
                showCustomMessage('Please select an audio file first!');
                return;
            }

            if (!audioContext || audioContext.state === 'suspended') {
                initAudioContext(); // Initialize or resume context
            }

            if (isPlaying) {
                audio.pause();
                audioContext.suspend(); // Suspend audio context to save resources
                playPauseBtn.textContent = 'Play';
            } else {
                audio.play();
                audioContext.resume(); // Resume audio context
                playPauseBtn.textContent = 'Pause';
            }
            isPlaying = !isPlaying;
        });

        // Event listener for Stop button
        stopBtn.addEventListener('click', function() {
            if (audio.src) {
                audio.pause();
                audio.currentTime = 0; // Reset audio to beginning
                if (audioContext) {
                    audioContext.suspend(); // Suspend audio context
                }
                playPauseBtn.textContent = 'Play';
                isPlaying = false;
                // Clear the canvas when stopped
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                }
                canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
            }
        });

        // Event listener for Volume slider
        volumeSlider.addEventListener('input', function() {
            if (gainNode) {
                gainNode.gain.value = this.value; // Update gain node volume
            } else {
                // Fallback for direct audio element volume if Web Audio API isn't fully initialized
                audio.volume = this.value;
            }
        });

        // Handle audio ending
        audio.addEventListener('ended', function() {
            isPlaying = false;
            playPauseBtn.textContent = 'Play';
            if (audioContext) {
                audioContext.suspend(); // Suspend context when audio ends
            }
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height); // Clear visualizer
        });

        // Basic responsive canvas resizing (adjusts canvas internal resolution)
        function resizeCanvas() {
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
        }

        // Call resize on load and window resize
        window.addEventListener('load', resizeCanvas);
        window.addEventListener('resize', resizeCanvas);

        // Custom message box function (instead of alert)
        function showCustomMessage(message) {
            const messageBox = document.createElement('div');
            messageBox.className = 'fixed top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-gray-900 text-white p-6 rounded-lg shadow-xl border border-gray-700 z-50 text-center';
            messageBox.innerHTML = `
                <p class="text-xl mb-4">${message}</p>
                <button class="px-5 py-2 bg-blue-600 hover:bg-blue-700 rounded-md text-white font-medium" onclick="this.parentNode.remove()">OK</button>
            `;
            document.body.appendChild(messageBox);
            setTimeout(() => {
                if(messageBox.parentNode) messageBox.parentNode.removeChild(messageBox);
            }, 3000); // Auto-remove after 3 seconds
        }

        // IMPORTANT: Start the animation/visualization loop only after an audio file is loaded and played,
        // as Web Audio API requires user interaction to start.
        // The drawVisualizer is called within initAudioContext which is triggered by play/pause.
    </script>
</body>
</html>
